<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://tomdemeyere.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://tomdemeyere.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-03-26T17:35:35+00:00</updated><id>https://tomdemeyere.github.io/feed.xml</id><title type="html">blank</title><entry><title type="html">Use Parsl to create concurrent computational chemistry workflows</title><link href="https://tomdemeyere.github.io/blog/2024/workflows-manager-for-dft/" rel="alternate" type="text/html" title="Use Parsl to create concurrent computational chemistry workflows"/><published>2024-03-20T21:00:00+00:00</published><updated>2024-03-20T21:00:00+00:00</updated><id>https://tomdemeyere.github.io/blog/2024/-workflows-manager-for-dft</id><content type="html" xml:base="https://tomdemeyere.github.io/blog/2024/workflows-manager-for-dft/"><![CDATA[<p>A few weeks ago I posted my <a href="https://tomdemeyere.github.io/blog/2024/quacc-espresso/">first blog post</a> where I explained how to use the new Quantum Accelerator (Quacc) package to run DFT calculations with Quantum Espresso. In this blog post, I will show you how to use Quacc in combination with the Parsl workflow engine to create concurrent workflows for DFT calculations. This will allow you to run multiple calculations concurrently on your local machine or on a high-performance computing cluster.</p> <h3 id="quacc--parsl-tutorial">Quacc &amp; Parsl tutorial</h3> <p>If you never run a Quacc calculation before, I recommend you to either read the <a href="https://quantum-accelerators.github.io/quacc/">Quacc documentation</a> or read my previous blog post. In this blog post, I will assume you have Quacc installed and that you have set up the configuration file correctly.</p> <p>Before we start, you will need to install <a href="https://parsl-project.org">Parsl</a>:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>parsl
</code></pre></div></div> <p>Now that you have Parsl installed, you can configure Quacc to use this workflow engine by changing your .quacc.yaml:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>quacc <span class="nb">set </span>WORKFLOW_ENGINE parsl
</code></pre></div></div> <p>For the purpose of this tutorial, I will assume a similar setup than in my previous blog-post:</p> <ul> <li><code class="language-plaintext highlighter-rouge">ESPRESSO_PSEUDO</code> is set to a folder that contains the full <a href="https://www.materialscloud.org/discover/sssp/table/efficiency">SSSP 1.3.0 efficiency</a> pseudopotential library.</li> <li><code class="language-plaintext highlighter-rouge">ESPRESSO_BIN_DIR</code> is set to the path of the Quantum Espresso binaries.</li> </ul> <p>The aim of the tutorial is to compute the phonon dispersion of multiple bulk crystals using the espresso <code class="language-plaintext highlighter-rouge">ph.x</code> code. The <code class="language-plaintext highlighter-rouge">grid_phonon_flow</code> <a href="https://quantum-accelerators.github.io/quacc/reference/quacc/recipes/espresso/phonons.html#quacc.recipes.espresso.phonons.grid_phonon_flow">available in Quacc</a> will make this problem embarrassingly parallel by performing each representation of each q-points separately. Using Parsl these calculations are then done concurrently automatically depending on the resources available.</p> <p>The base code to run this calculation is fairly simple, it first runs a variable-cell relaxation, and then uses the results to run the phonon calculation. From there we can extract the force constant using <code class="language-plaintext highlighter-rouge">q2r.x</code> and then call <code class="language-plaintext highlighter-rouge">matdyn.x</code> to compute the phonon dispersion on an arbitrary q-point grid. The main function is described below, for now, let’s skip the technical details and focus on the functions being called:</p> <ul> <li><code class="language-plaintext highlighter-rouge">grid_phonon_flow</code> is a pre-made <code class="language-plaintext highlighter-rouge">@flow</code> in Quacc, that contains multiple <code class="language-plaintext highlighter-rouge">@job</code>, details can be found in the documentation.</li> <li><code class="language-plaintext highlighter-rouge">q2r_job</code> is a pre-made <code class="language-plaintext highlighter-rouge">@job</code> that runs the <code class="language-plaintext highlighter-rouge">q2r.x</code>.</li> <li><code class="language-plaintext highlighter-rouge">matdyn_job</code> is a pre-made <code class="language-plaintext highlighter-rouge">@job</code> that runs the <code class="language-plaintext highlighter-rouge">matdyn.x</code>.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@subflow</span>
<span class="k">def</span> <span class="nf">grid_phonon_dos_subflow</span><span class="p">(</span><span class="n">atoms_list</span><span class="p">):</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">atoms</span> <span class="ow">in</span> <span class="n">atoms_list</span><span class="p">:</span>
        <span class="n">grid_phonon_results</span> <span class="o">=</span> <span class="nf">grid_phonon_flow</span><span class="p">(</span>
            <span class="n">atoms</span><span class="p">,</span>
            <span class="n">job_params</span><span class="o">=</span><span class="n">grid_phonon_params</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">q2r_results</span> <span class="o">=</span> <span class="nf">q2r_job</span><span class="p">(</span><span class="n">grid_phonon_results</span><span class="p">[</span><span class="sh">"</span><span class="s">dir_name</span><span class="sh">"</span><span class="p">],</span> <span class="o">**</span><span class="n">q2r_params</span><span class="p">)</span>
        <span class="n">matdyn_results</span> <span class="o">=</span> <span class="nf">matdyn_job</span><span class="p">(</span><span class="n">q2r_results</span><span class="p">[</span><span class="sh">"</span><span class="s">dir_name</span><span class="sh">"</span><span class="p">],</span> <span class="o">**</span><span class="n">matdyn_params</span><span class="p">)</span>
        <span class="n">results</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">matdyn_results</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">results</span>
</code></pre></div></div> <p>The aim is then simple, we take a list of ASE <code class="language-plaintext highlighter-rouge">Atoms</code> objects, and we run this custom workflow for each of them. Each results are then stored in a list and returned.</p> <hr/> <h5 id="setting-up-parsl"><strong>Setting up Parsl</strong></h5> <p>You will need to configure Parsl before using it. In this tutorial, Parsl is run locally and will submit each job to an HPC scheduler (Slurm in this tutorial). All these options need to be specified via the Parsl configuration. Of course, as done similarly in my previous post, you can perfectly run this code without setting up any workflow engine.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">parsl.config</span> <span class="kn">import</span> <span class="n">Config</span>
<span class="kn">from</span> <span class="n">parsl.executors</span> <span class="kn">import</span> <span class="n">HighThroughputExecutor</span>
<span class="kn">from</span> <span class="n">parsl.launchers</span> <span class="kn">import</span> <span class="n">SimpleLauncher</span>
<span class="kn">from</span> <span class="n">parsl.providers</span> <span class="kn">import</span> <span class="n">SlurmProvider</span>

<span class="n">CONFIG</span> <span class="o">=</span> <span class="nc">Config</span><span class="p">(</span>
    <span class="n">executors</span><span class="o">=</span><span class="p">[</span>
        <span class="nc">HighThroughputExecutor</span><span class="p">(</span>
            <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">short-large</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">max_workers</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>  <span class="c1"># max number of @job to run concurently.
</span>            <span class="n">cores_per_worker</span><span class="o">=</span><span class="mf">1.0e-6</span><span class="p">,</span>  <span class="c1"># number of cores per worker, &lt; 1 to oversubscribe.
</span>            <span class="n">provider</span><span class="o">=</span><span class="nc">SlurmProvider</span><span class="p">(</span>
                <span class="n">account</span><span class="o">=</span><span class="sh">"</span><span class="s">e89-soto</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># your account code.
</span>                <span class="n">qos</span><span class="o">=</span><span class="sh">"</span><span class="s">short</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># which quality of service.
</span>                <span class="n">worker_init</span><span class="o">=</span><span class="n">worker_init</span><span class="p">,</span>  <span class="c1"># bash lines that will run before each @job
</span>                <span class="n">walltime</span><span class="o">=</span><span class="sh">"</span><span class="s">00:20:00</span><span class="sh">"</span><span class="p">,</span>
                <span class="n">nodes_per_block</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>  <span class="c1"># nodes for each slurm job (block)
</span>                <span class="n">cores_per_node</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># How many threads to use per parsl worker.
</span>                <span class="n">partition</span><span class="o">=</span><span class="sh">"</span><span class="s">standard</span><span class="sh">"</span><span class="p">,</span>
                <span class="n">init_blocks</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>  <span class="c1"># To be kept to 0, especially if you are using different executors.
</span>                <span class="n">max_blocks</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># Max number of slurm_jobs.
</span>                <span class="n">launcher</span><span class="o">=</span><span class="nc">SimpleLauncher</span><span class="p">(),</span>  <span class="c1"># Control where Parsl will live,
</span>            <span class="p">),</span>
        <span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">parsl</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">CONFIG</span><span class="p">)</span>
</code></pre></div></div> <p>The terminology is a bit different from what you might be used to, here is a quick summary:</p> <ul> <li> <p><code class="language-plaintext highlighter-rouge">blocks</code> is the number of actual Slurm jobs. You have total control over that by using the keywords <code class="language-plaintext highlighter-rouge">init_blocks</code>, <code class="language-plaintext highlighter-rouge">min_blocks</code> and <code class="language-plaintext highlighter-rouge">max_blocks</code>. By default, the pilot job model is used, which means that <code class="language-plaintext highlighter-rouge">max_blocks = 1</code>, you can increase this number to fit your needs.</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">workers</code> is also a concept introduced by Parsl, this is a computing unit that will take care of running a <code class="language-plaintext highlighter-rouge">@job</code>. In practice, this number will dictate how many of your <code class="language-plaintext highlighter-rouge">@job</code>’s can run concurrently.</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">launcher</code> dictates how the Parsl command is wrapped before being launched, the <code class="language-plaintext highlighter-rouge">SimpleLauncher</code> used here means that it does not use any wrapping; the Parsl process will only run on the mother node. The <code class="language-plaintext highlighter-rouge">SingleNodeLauncher</code> will run the parsl process on each node, and might be used as well.</p> </li> <li> <p><code class="language-plaintext highlighter-rouge">cores_per_worker</code> is the number of cores that will be used by each worker. In the case of computational chemistry, you will often see that it is set to something very low, this means that multiple workers can live on the same threads. There is no need to tweak <code class="language-plaintext highlighter-rouge">cores_per_node</code>.</p> </li> </ul> <p>These parallelization options are not to be seen as the ones that will affect your individual DFT calculations but more as a <strong>total</strong> parallelization that will dictate how many resources this <code class="language-plaintext highlighter-rouge">executor</code> can use. Your DFT calculations are then dispatched inside this executor, their parallelization will be specified later.</p> <p><code class="language-plaintext highlighter-rouge">worker_init</code> should have everything you need to run espresso, the machine I use does not have access to the home system from the compute nodes, so I need to to load a ‘scratch’ bashrc that contains the conda init. This is done by adding the following lines:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">worker_init</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">
source /path/inside/scratch/.bashrc # Load your bashrc that contains the conda init.
conda activate quacc # Activate the conda environment.

export QUACC_CONFIG_FILE=/path/inside/scratch/.quacc.yaml # Quacc config in scratch space.

module load PrgEnv-gnu
module load cray-fftw cray-hdf5-parallel

export LD_LIBRARY_PATH=$CRAY_LD_LIBRARY_PATH:$LD_LIBRARY_PATH
</span><span class="sh">"""</span>
</code></pre></div></div> <hr/> <h5 id="specifying-parameters-and-parallelization"><strong>Specifying parameters and parallelization</strong></h5> <p>Before running the workflow you need to setup the parameters that will be sent to each flow and job, namely the <code class="language-plaintext highlighter-rouge">grid_phonon_params</code>, <code class="language-plaintext highlighter-rouge">matdyn_params</code>, and <code class="language-plaintext highlighter-rouge">q2r_params</code>. For the parallelization, currently, the Quacc Espresso interface uses the new <code class="language-plaintext highlighter-rouge">parallel_info</code> mechanism introduced in ASE. Here we will use the <code class="language-plaintext highlighter-rouge">srun</code> command with its options. This is done by setting the <code class="language-plaintext highlighter-rouge">parallel_info</code> variable in the <code class="language-plaintext highlighter-rouge">grid_phonon_params</code> and <code class="language-plaintext highlighter-rouge">matdyn_params</code> dictionaries.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">parallel_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">binary</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">srun</span><span class="sh">"</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">-vv</span><span class="sh">"</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">--hint=nomultithread</span><span class="sh">"</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">--distribution=block:block</span><span class="sh">"</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">-N</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">-n</span><span class="sh">"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">-c</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">pw_input_data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">control</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span><span class="sh">"</span><span class="s">forc_conv_thr</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.0001</span><span class="p">},</span>
    <span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">occupations</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">smearing</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">degauss</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">smearing</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">cold</span><span class="sh">"</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="sh">"</span><span class="s">electrons</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span><span class="sh">"</span><span class="s">conv_thr</span><span class="sh">"</span><span class="p">:</span> <span class="mf">1e-12</span><span class="p">,</span> <span class="sh">"</span><span class="s">mixing_mode</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">TF</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">mixing_beta</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.7</span><span class="p">},</span>
    <span class="sh">"</span><span class="s">ions</span><span class="sh">"</span><span class="p">:</span> <span class="p">{},</span>
    <span class="sh">"</span><span class="s">cell</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span><span class="sh">"</span><span class="s">press_conv_thr</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">},</span>
<span class="p">}</span>

<span class="n">ph_input_data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">inputph</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">tr2_ph</span><span class="sh">"</span><span class="p">:</span> <span class="mf">1.0e-12</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">alpha_mix(1)</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">nmix_ph</span><span class="sh">"</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">ldisp</span><span class="sh">"</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">nq1</span><span class="sh">"</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">nq2</span><span class="sh">"</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">nq3</span><span class="sh">"</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">}</span>

<span class="n">matdyn_input_data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">input</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">asr</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">crystal</span><span class="sh">"</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">dos</span><span class="sh">"</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">nk1</span><span class="sh">"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">nk2</span><span class="sh">"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">nk3</span><span class="sh">"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">deltaE</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">}</span>

<span class="n">grid_phonon_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">relax_job</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">input_data</span><span class="sh">"</span><span class="p">:</span> <span class="n">pw_input_data</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">kspacing</span><span class="sh">"</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">relax_cell</span><span class="sh">"</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">parallel_info</span><span class="sh">"</span><span class="p">:</span> <span class="n">parallel_info</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="sh">"</span><span class="s">ph_job</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span>
        <span class="sh">"</span><span class="s">input_data</span><span class="sh">"</span><span class="p">:</span> <span class="n">ph_input_data</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">parallel_info</span><span class="sh">"</span><span class="p">:</span> <span class="n">parallel_info</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">}</span>

<span class="n">matdyn_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">input_data</span><span class="sh">"</span><span class="p">:</span> <span class="n">matdyn_input_data</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">parallel_info</span><span class="sh">"</span><span class="p">:</span> <span class="n">parallel_info</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">q2r_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">parallel_info</span><span class="sh">"</span><span class="p">:</span> <span class="n">parallel_info</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div> <p>All these lines and config are to be placed before the <code class="language-plaintext highlighter-rouge">@subflow</code> “grid_phonon_dos_subflow”. You can access the complete script on my GitHub page. At this point, you can create an atoms list of bulk crystals and call the function.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">ase.build</span> <span class="kn">import</span> <span class="n">bulk</span>

<span class="n">atoms_list</span> <span class="o">=</span> <span class="p">[</span>
    <span class="nf">bulk</span><span class="p">(</span><span class="sh">"</span><span class="s">Al</span><span class="sh">"</span><span class="p">,</span> <span class="n">cubic</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
    <span class="nf">bulk</span><span class="p">(</span><span class="sh">"</span><span class="s">Cu</span><span class="sh">"</span><span class="p">,</span> <span class="n">cubic</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
    <span class="nf">bulk</span><span class="p">(</span><span class="sh">"</span><span class="s">Ag</span><span class="sh">"</span><span class="p">,</span> <span class="n">cubic</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
    <span class="nf">bulk</span><span class="p">(</span><span class="sh">"</span><span class="s">Au</span><span class="sh">"</span><span class="p">,</span> <span class="n">cubic</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
    <span class="nf">bulk</span><span class="p">(</span><span class="sh">"</span><span class="s">Ni</span><span class="sh">"</span><span class="p">,</span> <span class="n">cubic</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
    <span class="nf">bulk</span><span class="p">(</span><span class="sh">"</span><span class="s">Pd</span><span class="sh">"</span><span class="p">,</span> <span class="n">cubic</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
    <span class="nf">bulk</span><span class="p">(</span><span class="sh">"</span><span class="s">Pt</span><span class="sh">"</span><span class="p">,</span> <span class="n">cubic</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
    <span class="nf">bulk</span><span class="p">(</span><span class="sh">"</span><span class="s">Li</span><span class="sh">"</span><span class="p">,</span> <span class="n">cubic</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
<span class="p">]</span>

<span class="n">future</span> <span class="o">=</span> <span class="nf">grid_phonon_dos_flow</span><span class="p">(</span><span class="n">atoms_list</span><span class="p">)</span>
</code></pre></div></div> <p>At this stage, running the Python script doesn’t produce any output. This is because Parsl is now handling the function call, and it is only generating the <a href="(https://en.wikipedia.org/wiki/Directed\_acyclic\_graph)">Directed Acyclic Graph (DAG)</a>, which is an internal representation of the workflow. The returned object is a future object. To actually execute the workflow, the future object needs to be resolved by calling the <code class="language-plaintext highlighter-rouge">Future.result()</code> method.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">results</span> <span class="o">=</span> <span class="n">future</span><span class="p">.</span><span class="nf">result</span><span class="p">()</span>
</code></pre></div></div> <p>If you have important disparities between the size of your jobs, Parsl allows you to define multiple executors. To do this, you just need to add a new executor to the <code class="language-plaintext highlighter-rouge">CONFIG</code> object. You simply need to add one more executor to the list. I will not show it here, but the code is available on my <a href="">GitHub</a>. Using Quacc each job can be linked to a single executor to make sure to run your jobs using the resources you want.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">q2r_job_custom</span> <span class="o">=</span> <span class="nf">redecorate</span><span class="p">(</span><span class="n">q2r_job</span><span class="p">,</span> <span class="nf">job</span><span class="p">(</span><span class="n">executors</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">q2r</span><span class="sh">"</span><span class="p">]))</span>
<span class="n">matdyn_job_custom</span> <span class="o">=</span> <span class="nf">redecorate</span><span class="p">(</span><span class="n">matdyn_job</span><span class="p">,</span> <span class="nf">job</span><span class="p">(</span><span class="n">executors</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">matdyn</span><span class="sh">"</span><span class="p">]))</span>
</code></pre></div></div> <hr/> <h5 id="what-will-happen-exactly"><strong>What will happen exactly?</strong></h5> <p>Parsl will construct the workflow internally and be able to manage the intresic dependencies between the jobs. Two jobs that do not depends on each other can possibly run at the same time. To make things clearer I made the diagram below that summarize what is happening.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/grid_phonon_flow-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/grid_phonon_flow-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/grid_phonon_flow-1400.webp"/> <img src="/assets/img/grid_phonon_flow.png" class="img-fluid rounded" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Schematic of the workflow, all `Atoms` object will run concurently, similarly all identical colors within each subtask can run concurently as well. This makes the problem embarrassingly parallel. </div> <p>Depending on the number of workers you have set, you will see as many concurrent calculations, other tasks will be queued and run as soon as a worker is available.</p> <hr/> <h5 id="where-is-the-output"><strong>Where is the output?</strong></h5> <p>When using Parsl things are a little bit different, the output will mainly be located in the <code class="language-plaintext highlighter-rouge">runinfo</code> dir located in the current working directory. This directory will contain a lot of information about the workflow, including the Parsl logs. You can see the log for each worker in the <code class="language-plaintext highlighter-rouge">runinfo/&lt;executor_label&gt;</code> directory.</p> <hr/> <h5 id="i-want-to-use-a-different-interface-then-slurmsrun-how"><strong>I want to use a different interface then slurm/srun, how?</strong></h5> <p>Parsl is very flexible and can be used with a <a href="https://parsl.readthedocs.io/en/stable/userguide/configuring.html">lot of different interfaces</a>. The <code class="language-plaintext highlighter-rouge">SlurmProvider</code> is only one of them. However, running MPI apps is a tricky business, as of now (25th March 2024), Quacc does not support command that do not automatically allocate ressources for a job such as mpirun/mpiexec or other exotic executables. The underlying technical reason is that Quacc do not communicate to Parsl the size of each job. This is currently <a href="https://github.com/Quantum-Accelerators/quacc/issues/1886">being implemented</a>.</p> <hr/> <h5 id="what-if-one-job-fails"><strong>What if one job fails?</strong></h5> <p>Parsl is able to handle this, if a job fails, every other jobs that do not have the failed job as a dependency will run. This is a very powerful feature that allows to run high-throughput workflows without having to worry about too much about the stability of the system. Be aware that the <code class="language-plaintext highlighter-rouge">future.result()</code> will still raise an exception if a job fails.</p>]]></content><author><name></name></author><category term="Quacc"/><category term="DFT"/><category term="Espresso"/><category term="Parsl"/><summary type="html"><![CDATA[Quacc & Parsl, concurrent workflows for DFT calculations.]]></summary></entry><entry><title type="html">Use the Quantum Accelerator to improve your DFT calculations</title><link href="https://tomdemeyere.github.io/blog/2024/quacc-espresso/" rel="alternate" type="text/html" title="Use the Quantum Accelerator to improve your DFT calculations"/><published>2024-02-04T21:00:00+00:00</published><updated>2024-02-04T21:00:00+00:00</updated><id>https://tomdemeyere.github.io/blog/2024/quacc-espresso</id><content type="html" xml:base="https://tomdemeyere.github.io/blog/2024/quacc-espresso/"><![CDATA[<p>Not long ago, I was looking at the <a href="https://wiki.fysik.dtu.dk/ase/">Atomic Simulation Environment</a> (ASE) <a href="https://wiki.fysik.dtu.dk/ase/ecosystem.html">ecosystem page</a>, when I noticed a new contender: The Quantum Accelerator (Quacc) from the <a href="https://rosen.cbe.princeton.edu">Rosen group</a> at Princeton. It is a new Python package that aims to connect computational chemistry codes to various workflow engines. I quickly got hooked and tried to use it for my work. The package runs around the Atomic Simulation Environment (ASE) and provides recipes and presets to run calculations with ease. You don’t necessarily have to use a workflow engine to use it, this tutorial will not use any. <a href="https://quantum-accelerators.github.io/quacc/install/install.html#installing-quacc">The installation</a> is pretty standard, the only important thing is that you will need the latest ASE version from git before installing it.</p> <p>Unfortunately, at the time there was no implementation for Quantum Espresso, I did my own and merged it to the main repository. If you know how to use the ASE Espresso interface, Quacc will not be difficult to get your head around.</p> <h3 id="espresso-tutorial">Espresso tutorial</h3> <p>Before running everything, Quacc has a configuration file that you must setup correctly to run Espresso calculations. Two important things to set are the path to the Espresso binary and the pseudopotential directory. This configuration file is by default located at <code class="language-plaintext highlighter-rouge">~/.quacc.yaml</code>. Let’s use the CLI to set it up:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Setting ESPRESSO_BIN_DIR is not needed if pw.x is in your PATH</span>
quacc <span class="nb">set </span>ESPRESSO_BIN_DIR /path/to/espresso/bin
quacc <span class="nb">set </span>ESPRESSO_PSEUDO /path/to/espresso/pseudopotentials
</code></pre></div></div> <p>If you open the configuration file you should notice the changes. For the purpose of this tutorial, you will need to set the <code class="language-plaintext highlighter-rouge">ESPRESSO_PSEUDO</code> setting to a folder that contains the full <a href="https://www.materialscloud.org/discover/sssp/table/efficiency">SSSP 1.3.0 efficiency</a> pseudopotential library.</p> <p>Now, let’s try to run a simple calculation. Quacc contains recipes and everything is done under the hood, no need for you to write input files. Let’s try to run a simple calculation for a bulk system.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">ase.build</span> <span class="kn">import</span> <span class="n">bulk</span>
<span class="kn">from</span> <span class="n">quacc.recipes.espresso.core</span> <span class="kn">import</span> <span class="n">static_job</span>

<span class="n">atoms</span> <span class="o">=</span> <span class="nf">bulk</span><span class="p">(</span><span class="sh">"</span><span class="s">Si</span><span class="sh">"</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="nf">static_job</span><span class="p">(</span><span class="n">atoms</span><span class="p">)</span>
</code></pre></div></div> <p><strong>That’s it! You just ran a DFT calculation!</strong></p> <hr/> <h5 id="where-are-the-results"><strong>Where are the results?</strong></h5> <p>Results are stored in the variable <code class="language-plaintext highlighter-rouge">results</code> which is a dictionary.</p> <ul> <li><code class="language-plaintext highlighter-rouge">results["atoms"]</code> contains the final ASE Atoms object.</li> <li><code class="language-plaintext highlighter-rouge">results["results"]</code> contains results from the ASE calculator, such as the energy, forces…</li> <li><code class="language-plaintext highlighter-rouge">results["input_atoms"]</code> contains information about atoms sent to the job.</li> <li><code class="language-plaintext highlighter-rouge">results["dir_name"]</code> contains the directory where the calculation was ran.</li> </ul> <p>There are other keys in the dictionary, but these are the most important ones. Printing the dictionary will give you a better idea of what’s inside.</p> <p>For files, you will notice Quacc creating folders in the current working directory. Calculations are run in temporary folders and at the end files are moved and gzipped to a permanent folder. If this behaviour seems strange, it makes more sense when you consider the use of workflow engines. Settings are available to change the default behaviour; if you want more information about directory management, the Quacc documentation has a nice <a href="https://quantum-accelerators.github.io/quacc/user/settings/file_management.html">page</a> about it.</p> <hr/> <h5 id="how-do-i-change-the-espresso-keywords"><strong>How do I change the Espresso keywords?</strong></h5> <p>The static_job is pretty much a wrapper around the ASE Espresso calculator for this purpose. You can pass any parameter that you would pass to the Espresso calculator. Here are some examples:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># input_data in flat dictionary format
</span><span class="nf">static_job</span><span class="p">(</span><span class="n">atoms</span><span class="p">,</span> <span class="n">input_data</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">ecutwfc</span><span class="sh">"</span><span class="p">:</span> <span class="mi">40</span><span class="p">},</span> <span class="n">kpts</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="c1"># input_data in nested dictionary format, kspacing in units of 1/Å
</span><span class="nf">static_job</span><span class="p">(</span><span class="n">atoms</span><span class="p">,</span> <span class="n">input_data</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">system</span><span class="sh">"</span><span class="p">:</span> <span class="p">{</span><span class="sh">"</span><span class="s">ecutwfc</span><span class="sh">"</span><span class="p">:</span> <span class="mi">40</span><span class="p">}},</span> <span class="n">kspacing</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span>
</code></pre></div></div> <hr/> <h5 id="what-are-the-static_job-parameters"><strong>What are the static_job parameters?</strong></h5> <p>Let’s look at the static_job signature:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@job</span>
<span class="k">def</span> <span class="nf">static_job</span><span class="p">(</span>
    <span class="n">atoms</span><span class="p">:</span> <span class="n">Atoms</span><span class="p">,</span>
    <span class="n">preset</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="bp">None</span> <span class="o">=</span> <span class="sh">"</span><span class="s">sssp_1.3.0_pbe_efficiency</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">parallel_info</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">|</span> <span class="bp">None</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="n">test_run</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
    <span class="n">copy_files</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="n">Path</span> <span class="o">|</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span> <span class="o">|</span> <span class="n">Path</span><span class="p">]</span> <span class="o">|</span> <span class="bp">None</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">calc_kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RunSchema</span><span class="p">:</span>
</code></pre></div></div> <p>The preset parameter is the one that defines the pseudopotentials here, it is doing so by looking at a yaml file located in the <code class="language-plaintext highlighter-rouge">ESPRESSO_PRESET</code> directory. By default, this directory is located inside the Quacc package and no further setup is required. The custom Espresso calculator will look at the recommended cutoff for the elements in the calculation and take the highest one automatically. Preset files for Espresso can be browsed on the <a href="https://github.com/Quantum-Accelerators/quacc/tree/main/src/quacc/calculators/espresso/presets">Quacc github</a>. You will notice the existence of other presets such as “esm_metal_slab_efficiency.yaml” or “tough_metal_clusters_efficiency.yaml” which additionally change the <code class="language-plaintext highlighter-rouge">input_data</code>. <strong>Of course, any parameters manually passed that conflict with the preset will override it</strong>. If presets are not of interest to you, just set it to <code class="language-plaintext highlighter-rouge">None</code>.</p> <p>Let’s look at the other parameters, the <code class="language-plaintext highlighter-rouge">parallel_info</code> parameter is used to define the parallelization settings, ASE style. The <code class="language-plaintext highlighter-rouge">test_run</code> parameter is used to run a test calculation, it will create a “pwscf.EXIT” file which instructs pw.x to perform a dry-run, useful for checking that your input does not contain any errors. The <code class="language-plaintext highlighter-rouge">copy_files</code> parameter is used to copy files from specified directories to the calculation directory, useful for restarting for example.</p> <hr/> <h5 id="how-do-i-run-anything-else"><strong>How do I run anything else?</strong></h5> <p>I implemented various recipes in Quacc for Espresso, you can find them in the <a href="https://quantum-accelerators.github.io/quacc/user/recipes/recipes_list.html#quantum-espresso">documentation</a>. Since I recently extended the ASE Espresso interface to other binaries, it is now possible to use other binaries such as ph.x, pp.x, dos.x, etc…</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">quacc.recipes.espresso.core</span> <span class="kn">import</span> <span class="n">ase_relax_job</span>
<span class="kn">from</span> <span class="n">quacc.recipes.espresso.phonons</span> <span class="kn">import</span> <span class="n">phonon_job</span>

<span class="n">relax_results</span> <span class="o">=</span> <span class="nf">ase_relax_job</span><span class="p">(</span><span class="n">atoms</span><span class="p">)</span>
<span class="n">phonon_results</span> <span class="o">=</span> <span class="nf">phonon_job</span><span class="p">(</span><span class="n">relax_results</span><span class="p">[</span><span class="sh">"</span><span class="s">dir_name</span><span class="sh">"</span><span class="p">])</span>
</code></pre></div></div> <p>The above code will run a relaxation calculation using ASE optimizers and then run a phonon calculation using ph.x. Similarly, you can change the parameters of the phonon calculations by passing <code class="language-plaintext highlighter-rouge">input_data</code> and other parameters to the phonon_job function, everything should be described in the documentation. The Espresso calculator in Quacc takes care of activating restart keywords such as <code class="language-plaintext highlighter-rouge">startingpot</code> and <code class="language-plaintext highlighter-rouge">startingwfc</code> during the optimization phase to avoid starting from scratch at each step. Of course, if you want to use the Espresso internal optimizer, you can use the <code class="language-plaintext python highlighter-rouge">quacc.recipes.espresso.core.relax_job</code> function.</p> <hr/> <p>That’s it for this post! This is probably the first part of a series of posts about Quacc. Here is what to expect from the next blog posts:</p> <ol> <li> <p>Why do we need workflow engines; how to create your own workflows; how to run them on HPC.</p> </li> <li> <p>How to use a monkey-patched version of ASE’s NEB class to run calculations concurrently on HPC without the need for explicit parallel code.</p> </li> <li> <p>How to modify an ASE dynamics object to perform additional actions, such as projwfc.x or pp.x jobs at a predefined interval in an optimization or MD run.</p> </li> </ol> <p>In the meantime, if you are interested you can learn more by having a look at the <a href="https://quantum-accelerators.github.io/quacc/">Quacc documentation</a>. Or wait until I write a post about it in the coming days!</p> <script src="https://giscus.app/client.js" data-repo="tomdemeyere/tomdemeyere.github.io" data-repo-id="R_kgDOK8-7Kg" data-category="Comments" data-category-id="DIC_kwDOK8-7Ks4Cc9vt" data-mapping="title" data-strict="1" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="preferred_color_scheme" data-lang="en" crossorigin="anonymous" async=""> </script>]]></content><author><name></name></author><category term="Quacc"/><category term="DFT"/><category term="Espresso"/><category term="ASE"/><summary type="html"><![CDATA[I recently discovered Quacc and I implemented an interface for the Quantum Espresso code. Let's try it!]]></summary></entry></feed>